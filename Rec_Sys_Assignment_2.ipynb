{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uj4T8PEHGbMF"
      },
      "source": [
        "# Assignment 2\n",
        "## Question 1: Siamese networks & one-shot learning (7pt)\n",
        "The Cifar-100 dataset is similar to the Cifar-10 dataset. It also consists of 60,000 32x32 RGB images, but they are distributed over 100 classes instead of 10. Thus, each class has much fewer examples, only 500 training images and 100 testing images per class. For more info about the dataset, see https://www.cs.toronto.edu/~kriz/cifar.html.\n",
        "\n",
        "*HINT: Import the Cifar-100 dataset directly from Keras, no need to download it from the website. Use* `label_mode=\"fine\"`\n",
        "\n",
        "### Task 1.1: Siamese network\n",
        "**a)**\n",
        "* Train a Siamese Network on the first 80 classes of (the training set of) Cifar-100, i.e. let the network predict the probability that two input images are from the same class. Use 1 as a target for pairs of images from the same class (positive pairs), and 0 for pairs of images from different classes (negative pairs). Randomly select image pairs from Cifar-100, but make sure you train on as many positive pairs as negative pairs.\n",
        "\n",
        "* Evaluate the performance of the network on 20-way one-shot learning tasks. Do this by generating 250 random tasks and obtain the average accuracy for each evaluation round. Use the remaining 20 classes that were not used for training. The model should perform better than random guessing.\n",
        "\n",
        "For this question you may ignore the test set of Cifar-100; it suffices to use only the training set and split this, using the first 80 classes for training and the remaining 20 classes for one-shot testing.\n",
        "\n",
        "*HINT: First sort the data by their labels (see e.g.* `numpy.argsort()`*), then reshape the data to a shape of* `(n_classes, n_examples, width, height, depth)`*, similar to the Omniglot data in Practical 4. It is then easier to split the data by class, and to sample positive and negative images pairs for training the Siamese network.*\n",
        "\n",
        "*NOTE: do not expect the one-shot accuracy for Cifar-100 to be similar to that accuracy for Omniglot; a lower accuracy can be expected. However, accuracy higher than random guess is certainly achievable.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MaoAaEv17v6k",
        "outputId": "7a6f3175-b191-4eae-e86a-361f17d5a059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Lambda, Flatten, BatchNormalization, concatenate\n",
        "from keras.utils import to_categorical\n",
        "from keras.regularizers import l2\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.initializers import Zeros\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras import backend as K\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ7airbJ-Q19",
        "colab_type": "code",
        "outputId": "4f8fe609-12b6-46c2-9da6-978c194f88be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "path = F\"/content/gdrive/My Drive/Colab Notebooks/Assignment_2/\" "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ycYOk849wb-",
        "colab_type": "code",
        "outputId": "d2109979-7372-45df-840a-3b22918d067b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "(x,y), (xx, yy)=cifar100.load_data(label_mode=\"fine\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 13s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqRZwAoFkFV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(x,y):\n",
        "    y = y.flatten()\n",
        "    sort = np.argsort(y)\n",
        "    y = y[sort]\n",
        "    x = x[sort]\n",
        "\n",
        "    x=np.array(x, dtype=np.float64)\n",
        "    x /= 255\n",
        "    x = x.reshape(100,-1,32,32,3)\n",
        "    x_train = x[:80,:,:,:,:]\n",
        "    y_train = y[:int(x.shape[0]*x.shape[1]*0.8)]\n",
        "    x_test = x[80:,:,:,:,:]\n",
        "    y_test = y[int(x.shape[0]*x.shape[1]*0.8):]\n",
        "    \n",
        "    y_train = to_categorical(y_train,100)\n",
        "    y_test = to_categorical(y_test,100)\n",
        "    return x,y,x_train,y_train,x_test,y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XhKTFm8NnQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "The naming is not very understandable. x and y are the training set of Cifar-100, and xx, yy are the test set. \n",
        "x_train and y_train are the first 80 classes of the training set, and x_test and y_test are the last 20 classes of the training set.\n",
        "Likewise, xx_train and yy_train are the first 80 classes of the training set, and xx_test and yy_test are the last 20 classes of the training set.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "x,y,x_train,y_train,x_test,y_test = normalize(x,y)\n",
        "xx_t, yy_t, xx_train, yy_train, xx_test, yy_test = normalize(xx,yy) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_jjNF0EXvt",
        "colab_type": "code",
        "outputId": "883fcc53-564b-4767-dc57-caa54e1e5de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "#Visualizing\n",
        "example_class = np.random.randint(0,79)  # pick any integer from 0 to 80\n",
        "example_id = np.random.randint(0,499) # pick any integer from 0 to 499\n",
        "example = x_train[example_class][example_id]\n",
        "labels = [ 'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', \n",
        "          'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', \n",
        "          'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', \n",
        "          'computer_keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', \n",
        "          'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', \n",
        "          'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', \n",
        "          'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', \n",
        "          'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm', ]\n",
        "label = y_train[example_class*500+example_id]\n",
        "print(\"Class label:\", labels[np.argmax(label)])\n",
        "plt.imshow(example)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class label: aquarium_fish\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG50yg+EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mWYsebAjc3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = labels[:80]\n",
        "test_labels = labels[80:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl_GRnBnHOCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(batch_size, X):\n",
        "    \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
        "    n_classes, n_examples, w, h, r = X.shape \n",
        "    # for x_train. n_classes, n_examples, w, h, r = (80, 500, 32, 32, 3)\n",
        "    \n",
        "    # randomly sample several classes to use in the batch\n",
        "    categories = np.random.choice(n_classes, size=(batch_size,))\n",
        "\n",
        "    # initialize 2 empty arrays for the input image batch\n",
        "    pairs = [np.zeros((batch_size, h, w, r)) for i in range(2)]\n",
        "    # initialize vector for the targets, and make one half of it '1's, so 2nd half of batch has same class\n",
        "    targets = np.zeros((batch_size,))\n",
        "    targets[batch_size//2:] = 1\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        category = categories[i]\n",
        "        idx_1 = np.random.randint(n_examples)\n",
        "        pairs[0][i, :, :, :] = X[category, idx_1].reshape(w, h, r)\n",
        "        idx_2 = np.random.randint(n_examples)\n",
        "        # pick images of same class for 1st half, different for 2nd\n",
        "        if i >= batch_size // 2:\n",
        "            category_2 = category\n",
        "        else:\n",
        "            #add a random number to the category modulo n_classes to ensure 2nd image has different category\n",
        "            category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
        "        pairs[1][i, :, :, :] = X[category_2,idx_2].reshape(w, h, r)\n",
        "    return pairs, targets\n",
        "\n",
        "def batch_generator(batch_size, X):\n",
        "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
        "    while True:\n",
        "        pairs, targets = get_batch(batch_size, X)\n",
        "        yield (pairs, targets)\n",
        "\n",
        "def train_siamese_model(model, x_train, batch_size=64, steps_per_epoch=100, epochs=1):\n",
        "    model.fit_generator(batch_generator(batch_size, x_train), steps_per_epoch=steps_per_epoch, epochs=epochs,verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHGOyI3oikQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_oneshot_task(N, X, c):\n",
        "    \"\"\"Create pairs of (test image, support set image) with ground truth, for testing N-way one-shot learning.\"\"\"\n",
        "    n_classes, n_examples, w, h, r = X.shape\n",
        "    indices = np.random.randint(0, n_examples, size=(N,))\n",
        "    categories = np.random.choice(range(n_classes), size=(N,), replace=False)            \n",
        "    true_category = categories[0]\n",
        "    ex1, ex2 = np.random.choice(n_examples, replace=False, size=(2,))\n",
        "    test_image = np.asarray([X[true_category, ex1, :, :]]*N).reshape(N, w, h, r)\n",
        "    support_set = X[categories, indices, :, :]\n",
        "    support_set[0, :, :] = X[true_category, ex2]\n",
        "    support_set = support_set.reshape(N, w, h, r)\n",
        "    targets = np.zeros((N,))\n",
        "    targets[0] = 1\n",
        "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "    pairs = [test_image, support_set]\n",
        "    return pairs, targets\n",
        "\n",
        "def test_oneshot(model, X, c, N=20, k=250, verbose=True):\n",
        "    \"\"\"Test average N-way oneshot learning accuracy of a siamese neural net over k one-shot tasks.\"\"\"\n",
        "    n_correct = 0\n",
        "    if verbose:\n",
        "        print(\"Evaluating model on {} random {}-way one-shot learning tasks ...\".format(k, N))\n",
        "    for i in range(k):\n",
        "        inputs, targets = make_oneshot_task(N, X, c)\n",
        "        probs = model.predict(inputs)\n",
        "        if np.argmax(probs) == np.argmax(targets):\n",
        "            n_correct += 1\n",
        "    percent_correct = (100.0*n_correct / k)\n",
        "    if verbose:\n",
        "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\".format(percent_correct, N))\n",
        "    return percent_correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCowhxGYj8vP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_siamese_model():\n",
        "    input_shape = (32,32,3)\n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (4,4), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(256, (2,2), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation='sigmoid', kernel_regularizer=l2(1e-3)))\n",
        "    model.summary()\n",
        "\n",
        "    left_encoded = model(left_input)\n",
        "    right_encoded = model(right_input)\n",
        "    \n",
        "    # Add a customized layer to compute the absolute difference between the encodings\n",
        "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([left_encoded, right_encoded])\n",
        "\n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
        "\n",
        "    # Connect the inputs with the outputs\n",
        "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    siamese_net.compile(loss=\"binary_crossentropy\",optimizer=Adam(lr=0.00005))\n",
        "    return siamese_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ha6eHEvobAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_test_siamese_model(model=None,best_acc=0,loops=200, evaluate_every=10,save=True):\n",
        "    if not model:\n",
        "        model = get_siamese_model()\n",
        "    total_acc = 0\n",
        "    for i in range(loops):\n",
        "        train_siamese_model(model, x_train, batch_size=64, steps_per_epoch=100, epochs=1)\n",
        "        if i % evaluate_every == 0:\n",
        "            print(\"Training loop {} ===\".format(i))\n",
        "            acc = test_oneshot(model, x_test, test_labels, N=20, k=250, verbose=True)\n",
        "            total_acc += acc\n",
        "            if acc > best_acc:\n",
        "                best_acc = acc\n",
        "                if save:\n",
        "                    model.save(path+\"siamese_net.h5\")\n",
        "    print(f'Total accuracy: {total_acc / loops}')\n",
        "    print(f'Best accuracy: {best_acc}')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLt6nvlte-Lb",
        "colab_type": "code",
        "outputId": "30d8bcaa-648d-4ce7-9a16-06ea2ed852bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "#siamese_model = get_siamese_model()\n",
        "\n",
        "siamese_model = load_model(path+\"siamese_net.h5\")\n",
        "siamese_model = train_and_test_siamese_model(model=siamese_model,loops=10,evaluate_every=1,best_acc=0.3,save=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loop 0 ===\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 22.4% accuracy for 20-way one-shot learning\n",
            "Training loop 1 ===\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 27.6% accuracy for 20-way one-shot learning\n",
            "Training loop 2 ===\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 22.4% accuracy for 20-way one-shot learning\n",
            "Training loop 3 ===\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 23.6% accuracy for 20-way one-shot learning\n",
            "Training loop 4 ===\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 21.6% accuracy for 20-way one-shot learning\n",
            "Training loop 5 ===\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 21.6% accuracy for 20-way one-shot learning\n",
            "Training loop 6 ===\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 19.6% accuracy for 20-way one-shot learning\n",
            "Training loop 7 ===\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 21.6% accuracy for 20-way one-shot learning\n",
            "Training loop 8 ===\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 24.8% accuracy for 20-way one-shot learning\n",
            "Training loop 9 ===\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 22.0% accuracy for 20-way one-shot learning\n",
            "Total accuracy: 22.72\n",
            "Best accuracy: 27.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7f31ff9990f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "COiAqXWDAgCe"
      },
      "source": [
        "***\n",
        "\n",
        "**b)** Compare the performance of your Siamese network for Cifar-100 to the Siamese network from Practical 4 for Omniglot. Name three fundamental differences between the Cifar-100 and Omniglot datasets. How do these differences influence the difference in one-shot accuracy?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IIHkoQ0PBWuB"
      },
      "source": [
        "Clearly the Siamese network performs better, in terms of accuracy, on the Omniglot dataset. With the Cifar-100 dataset, we can get an accuracy of at most 30% for a batch of one-shot tasks, while with Omniglot dataset, we can get an accuracy around 35%, up to 40%.\n",
        "\n",
        "There are three major differences between the Omniglot and the Cifar-100 datasets which impact the result in performance. \n",
        "\n",
        "1.  Omniglot images have 105x105 resolution, while the data in the Cifar-100 dataset are 32x32 images. \n",
        "2.  Omniglot images are monochrome, while Cifar-100 images have a depth of 3, corresponding to RGB values.\n",
        "3.  Omniglot dataset has 50 classes, corresponding to 50 languages/scripts. In Cifar-100 dataset, there are 100 classes of objects. Siamese network for Omniglot case is trained on a subset of 30 scripts, while the network for Cifar-100 is trained on a subset of 80 classes. \n",
        "\n",
        "Lower resolution and colored images make classification a harder task. We might notice that we need a higher number of parameters to generate a network for the Omniglot dataset, but a higher number of parameters implies a more refined classification due to the possibility of detecting more features, while in the Cifar dataset the structure introduce much more noise, specially due to the resolution of the images. \n",
        "\n",
        "When using Cifar-100 the networks learns how to differentiate between a larger number of classes than Omniglot, therefore the distance metric that is supposed to be learned by the network can be arbitrarily more complicated, which can lead to a lower accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VWpFF_5-Bf4B"
      },
      "source": [
        "***\n",
        "\n",
        "### Task 1.2: One-shot learning with neural codes\n",
        "**a)**\n",
        "* Train a CNN classifier on the first 80 classes of Cifar-100. Make sure it achieves at least 40% classification accuracy on those 80 classes (use the test set to validate this accuracy).\n",
        "* Then use neural codes from one of the later hidden layers of the CNN with L2-distance to evaluate one-shot learning accuracy for the remaining 20 classes of Cifar-100 with 250 random tasks. I.e. for a given one-shot task, obtain neural codes for the test image as well as the support set. Then pick the image from the support set that is closest (in L2-distance) to the test image as your one-shot prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qU7rNa157v6r",
        "colab": {}
      },
      "source": [
        "def create_neural_code_model(x_train,y_train,n_classes):\n",
        "    \n",
        "    input_shape = (32,32,3)\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(128, (3,3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(Conv2D(128, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Conv2D(256, (2,2), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(n_classes, activation='softmax'))\n",
        "    model.summary()\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    batch_size = 64\n",
        "    epochs = 20\n",
        "    x_train, y_train = shuffle(x_train,y_train)\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iIoytCHXmPK",
        "colab_type": "code",
        "outputId": "4fe7d437-6d84-4147-8b3b-56d261fe6f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1231
        }
      },
      "source": [
        "neural_model = create_neural_code_model(x_train.reshape(40000,32,32,3),y_train,100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 13, 13, 256)       131328    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               4719104   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               51300     \n",
            "=================================================================\n",
            "Total params: 5,052,900\n",
            "Trainable params: 5,052,900\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "40000/40000 [==============================] - 14s 357us/step - loss: 3.7159 - acc: 0.1261\n",
            "Epoch 2/20\n",
            "40000/40000 [==============================] - 13s 328us/step - loss: 3.0212 - acc: 0.2521\n",
            "Epoch 3/20\n",
            "40000/40000 [==============================] - 13s 335us/step - loss: 2.6910 - acc: 0.3218\n",
            "Epoch 4/20\n",
            "40000/40000 [==============================] - 13s 330us/step - loss: 2.4582 - acc: 0.3693\n",
            "Epoch 5/20\n",
            "40000/40000 [==============================] - 13s 328us/step - loss: 2.2619 - acc: 0.4108\n",
            "Epoch 6/20\n",
            "40000/40000 [==============================] - 13s 328us/step - loss: 2.0991 - acc: 0.4498\n",
            "Epoch 7/20\n",
            "40000/40000 [==============================] - 13s 328us/step - loss: 1.9675 - acc: 0.4780\n",
            "Epoch 8/20\n",
            "40000/40000 [==============================] - 13s 328us/step - loss: 1.8411 - acc: 0.5087\n",
            "Epoch 9/20\n",
            "40000/40000 [==============================] - 13s 334us/step - loss: 1.7123 - acc: 0.5387\n",
            "Epoch 10/20\n",
            "40000/40000 [==============================] - 13s 331us/step - loss: 1.6016 - acc: 0.5670\n",
            "Epoch 11/20\n",
            "40000/40000 [==============================] - 13s 327us/step - loss: 1.4961 - acc: 0.5899\n",
            "Epoch 12/20\n",
            "40000/40000 [==============================] - 13s 328us/step - loss: 1.4087 - acc: 0.6111\n",
            "Epoch 13/20\n",
            "40000/40000 [==============================] - 13s 328us/step - loss: 1.3234 - acc: 0.6337\n",
            "Epoch 14/20\n",
            "40000/40000 [==============================] - 13s 332us/step - loss: 1.2519 - acc: 0.6513\n",
            "Epoch 15/20\n",
            "40000/40000 [==============================] - 13s 332us/step - loss: 1.1792 - acc: 0.6744\n",
            "Epoch 16/20\n",
            "40000/40000 [==============================] - 13s 331us/step - loss: 1.1140 - acc: 0.6884\n",
            "Epoch 17/20\n",
            "40000/40000 [==============================] - 13s 328us/step - loss: 1.0756 - acc: 0.6989\n",
            "Epoch 18/20\n",
            "40000/40000 [==============================] - 13s 329us/step - loss: 1.0135 - acc: 0.7171\n",
            "Epoch 19/20\n",
            "40000/40000 [==============================] - 13s 335us/step - loss: 0.9746 - acc: 0.7256\n",
            "Epoch 20/20\n",
            "40000/40000 [==============================] - 12s 308us/step - loss: 0.9242 - acc: 0.7440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpSzD1p6qQt2",
        "colab_type": "code",
        "outputId": "a6a5f90d-d2ba-4709-863a-469f4ae26a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "neural_model.evaluate(x=xx_train.reshape(8000,32,32,3), y=yy_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 1s 175us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.489718846201897, 0.454]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMs5Cn82Xm7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_oneshot_with_code(model, X, c, N=20, k=250, verbose=True):\n",
        "    \"\"\"Test average N-way oneshot learning accuracy of a siamese neural net over k one-shot tasks.\"\"\"\n",
        "    n_correct = 0\n",
        "    if verbose:\n",
        "        print(\"Evaluating model on {} random {}-way one-shot learning tasks ...\".format(k, N))\n",
        "    for i in range(k):\n",
        "        inputs, targets = make_oneshot_task(20, X, test_labels)\n",
        "        probs_1 = model.predict(inputs[0])\n",
        "        probs_2 = model.predict(inputs[1])\n",
        "        distances = [np.linalg.norm(x-y) for x,y in zip(probs_1,probs_2)]\n",
        "        if np.argmin(distances) == np.argmax(targets):\n",
        "            n_correct += 1\n",
        "    percent_correct = (100.0*n_correct / k)\n",
        "    if verbose:\n",
        "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\".format(percent_correct, N))\n",
        "    return percent_correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO8LfNWeo4Az",
        "colab_type": "code",
        "outputId": "8c0b5226-6e0e-4b3b-8be9-82d4c855cbe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        }
      },
      "source": [
        "neural_code_intermediate_model = Model(inputs=neural_model.input, outputs=neural_model.layers[-2].output)\n",
        "loops = 20\n",
        "acc = 0.0\n",
        "max_acc = 0.0\n",
        "for i in range(loops):\n",
        "    curr_acc = test_oneshot_with_code(neural_code_intermediate_model, x_test, test_labels)\n",
        "    if curr_acc > max_acc:\n",
        "        max_acc = curr_acc\n",
        "    acc += curr_acc\n",
        "print(\"Average accuracy: {}\".format(acc / loops))\n",
        "print(\"Maximum accuracy: {}\".format(max_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 9.6% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 10.4% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
            "Average accuracy: 13.88\n",
            "Maximum accuracy: 18.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M1BDzdPAz26B"
      },
      "source": [
        "***\n",
        "\n",
        "**b)** Briefly motivate your CNN architecture, and discuss the difference in one-shot accuracy between the Siamese network approach and the CNN neural codes approach.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oRpVm956FR8P"
      },
      "source": [
        "Our CNN architecture comes from both Internet search for best practices and from trial/error. Since we are getting a lower accuracy on our validation set, we tried to introduce regularization, dropout, and maxpooling layers to prevent overfitting. We are able to get ~45% accuracy on the test data for the first 80 classes. \n",
        "\n",
        "\n",
        "The difference in accuracy is very small for the Siamese network approach and CNN neural codes approach. This stems from the similarity of the approaches - both approaches are working on a single CNN that is used to achieve neural codes. The difference is, with the Siamese approach, the network also includes an L1 distance layer between the two twin networks, and backpropagation relies on the loss computed based on the result of this distance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p-gkaM1tCThc"
      },
      "source": [
        "***\n",
        "## Question 2: Triplet networks & one-shot learning (10pt)\n",
        "\n",
        "### Task 2.1: Train a triplet network\n",
        "**a)**\n",
        "* Train a triplet network on the first 80 classes of (the training set of) Cifar-100.\n",
        " \n",
        "* Make sure the network achieves a smaller loss than the margin and the network does not collapse all representations to zero vectors. *HINT: If you experience problems to achieve this goal, it might be helpful to tinker the learning rate.*\n",
        "\n",
        "* You are provided with a working example of triplet loss implementation for Keras below. You may directly use it.\n",
        "\n",
        "You may ignore the test set of Cifar-100 for this question as well. It suffices to use only the training set and split this, using the first 80 classes for training and the remaining 20 classes for one-shot testing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FIHD8l_rRLy5",
        "colab": {}
      },
      "source": [
        "# Notice that ground truth variable is not used for loss calculation. It is used as a function argument to by-pass some Keras functionality. \n",
        "# This is because the network structure already implies the ground truth for the anchor image with the \"positive\" image.\n",
        "import tensorflow as tf\n",
        "def triplet_loss(ground_truth, network_output):\n",
        "\n",
        "    anchor, positive, negative = tf.split(network_output, num_or_size_splits=3, axis=1)        \n",
        "\n",
        "    for embedding in [anchor, positive, negative]:\n",
        "        embedding = tf.math.l2_normalize(embedding)\n",
        "\n",
        "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=1)\n",
        "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=1)\n",
        "\n",
        "    margin = 0.2 # define your margin\n",
        "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), margin)\n",
        "    loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), axis=0)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfxMenEYMcME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_triplet_model():\n",
        "    input_shape = (32,32,3)\n",
        "    positive_input = Input(input_shape)\n",
        "    anchor_input = Input(input_shape)\n",
        "    negative_input = Input(input_shape)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (5,5), activation='relu', input_shape=input_shape,kernel_initializer='random_normal',))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(256, (2,2), activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.summary()\n",
        "\n",
        "    positive_encoded = model(positive_input)\n",
        "    anchor_encoded = model(anchor_input)\n",
        "    negative_encoded = model(negative_input)\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    concatvector = concatenate([anchor_encoded, positive_encoded, negative_encoded], axis=-1, name='merged_layer')\n",
        "    triplet_net = Model(inputs=[anchor_input,positive_input,negative_input],outputs=concatvector)\n",
        "    triplet_net.compile(loss=triplet_loss,optimizer=Adam(lr=0.0001)) \n",
        "    return triplet_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRPiuGzKPveV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "def get_triplet_batch(x,batch_size=128):\n",
        "    \"\"\"anchor_data = []\n",
        "    positive_data = []\n",
        "    negative_data = []\n",
        "    for i in range(80):\n",
        "        one_class = shuffle(x[i])\n",
        "        anchor_data.append(one_class[:250,:,:,:])\n",
        "        positive_data.append(one_class[250:,:,:,:])\n",
        "        rand_ind = np.random.randint(0,249)\n",
        "        const_neg_data = []\n",
        "        for j in range(250):\n",
        "            other_class = random.choice([a for a in range(0,80) if a != i])\n",
        "            const_neg_data.append(x[other_class,np.random.randint(0,499),:,:,:])\n",
        "        negative_data.append(const_neg_data)\n",
        "    anchor_data = np.asarray(anchor_data).reshape(-1,32,32,3)\n",
        "    positive_data = np.asarray(positive_data).reshape(-1,32,32,3)\n",
        "    negative_data = np.asarray(negative_data).reshape(-1,32,32,3)\"\"\"\n",
        "    \n",
        "    anchor_data = []\n",
        "    positive_data = []\n",
        "    negative_data = []\n",
        "    for j in range(batch_size):\n",
        "        i = np.random.randint(0,79)\n",
        "        anchor_data.append(x[i,np.random.randint(0,499),:,:,:])\n",
        "        positive_data.append(x[i,np.random.randint(0,499),:,:,:])\n",
        "        other_class = random.choice([a for a in range(0,80) if a != i])\n",
        "        negative_data.append(x[other_class,np.random.randint(0,499),:,:,:])\n",
        "    #print(len(anchor_data[0]))\n",
        "    anchor_data = np.asarray(anchor_data).reshape(-1,32,32,3)\n",
        "    positive_data = np.asarray(positive_data).reshape(-1,32,32,3)\n",
        "    negative_data = np.asarray(negative_data).reshape(-1,32,32,3)\n",
        "    \n",
        "    y_dummy = np.empty(batch_size)\n",
        "    \n",
        "    return [anchor_data,positive_data,negative_data], y_dummy\n",
        "    \n",
        "def triplet_batch_generator(batch_size, x):\n",
        "    while True:\n",
        "        pairs, targets = get_triplet_batch(x,batch_size)\n",
        "        yield (pairs, targets)\n",
        "\n",
        "def train_triplet_model_batch(model, x_train, batch_size=64, steps_per_epoch=100, epochs=1):\n",
        "    model.fit_generator(triplet_batch_generator(batch_size, x_train), steps_per_epoch=steps_per_epoch, epochs=epochs,verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUcn_nGpfyyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_triplet_model(model=None,best_acc=0,loops=200, evaluate_every=10):\n",
        "    if not model:\n",
        "        model = get_triplet_model()\n",
        "    for i in range(loops):\n",
        "        print(\"Training loop : {}\".format(i))\n",
        "        train_triplet_model_batch(model, x_train, batch_size=64, steps_per_epoch=100, epochs=1)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExcJQ7IraVak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.losses\n",
        "keras.losses.triplet_loss = triplet_loss\n",
        "triplet_model = load_model(path+\"triplet_model.h5\") #loading the module from drive, to avoid repeated training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXhSojjelJhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#triplet_model=train_triplet_model(model=triplet_model,loops=10,evaluate_every=1)\n",
        "#triplet_model.save(path+\"triplet_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XHGJp45AR1qm"
      },
      "source": [
        "***\n",
        "\n",
        "### Task 2.2: One-shot learning with triplet neural codes\n",
        "**a)**\n",
        "* Use neural codes from the triplet network with L2-distance to evaluate one-shot learning accuracy for the remaining 20 classes of Cifar-100 with 250 random tasks. I.e. for a given one-shot task, obtain neural codes for the test image as well as the support set. Then pick the image from the support set that is closest (in L2-distance) to the test image as your one-shot prediction.\n",
        "* Explicitly state the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FSUT9zlbHJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "triplet_network_intermediate_model = Sequential()\n",
        "for layer in triplet_model.layers[3].layers:\n",
        "    triplet_network_intermediate_model.add(layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L598c7GZ--8",
        "colab_type": "code",
        "outputId": "e5d56c20-60a6-408e-ede4-9c90f668bf5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "loops = 10\n",
        "acc = 0.0\n",
        "max_acc = 0.0\n",
        "for i in range(loops):\n",
        "    curr_acc = test_oneshot_with_code(triplet_network_intermediate_model, x_test, test_labels)\n",
        "    if curr_acc > max_acc:\n",
        "        max_acc = curr_acc\n",
        "    acc += curr_acc\n",
        "print(\"Average accuracy: {}\".format(acc / loops))\n",
        "print(\"Maximum accuracy: {}\".format(max_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 19.2% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 20.0% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 20.0% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 19.6% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 18.8% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 22.8% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 23.6% accuracy for 20-way one-shot learning\n",
            "Average accuracy: 19.159999999999997\n",
            "Maximum accuracy: 23.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CCcmbz0UU7mR"
      },
      "source": [
        "***\n",
        "## Question 3: Performance comparison (3pt)\n",
        "\n",
        "\n",
        "**a)** What accuracy would random guessing achieve (on average) on this dataset? Motivate your answer briefly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BKGDydqsVVX1"
      },
      "source": [
        "Random guessing would achieve 5% accuracy. There are 20 classes into which the images can be classified. A random guess, on average, would be correct 1 out of 20 times, hence 5%. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5KLXRv-eV04Q"
      },
      "source": [
        "**b)** Discuss and compare the performances of networks in tasks 1.1, 1.2 and 2.2. Briefly motivate and explain which task would be expected the highest accuracy. Explain the reasons of the accuracy difference if there are any. If there is almost no difference accuracy, explain the reason for that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "71kTHFBkcjp8"
      },
      "source": [
        "In theory, neural codes that we get after training the triplet network should have the highest accuracy. This follows from the triplet loss: the network learns in a way to maximize the distance between two images when they do not belong to the same class, while trying to minimize the distance between two images when they indeed belong to the same class. On the other hand, the Siamese network tries to optimize to find whether two images are of the same class - the loss is binary cross-entropy. This subtle difference makes triplet network more powerful, as the authors of papers that have used triplet networks show. \n",
        "\n",
        "However, in our implementations and experiments, we observe quite similar results for the methods in 1.1 and 2.2. In fact, Siamese network and neural codes from Triplet network give similar accuracies, around the band of 25%, whereas neural codes from Siamese network gives an accuracy around the band of 20%. The difference is not very extreme, and we believe the difference is the repeated batch training that we apply on Siamese network and Triplet network, allowing for better fitting the data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1yr4SY19XLY",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## Question 4: Peer review (0pt)\n",
        "\n",
        "Finally, each group member must write a single paragraph outlining their opinion on the work distribution within the group. Did every group member contribute equally? Did you split up tasks in a fair manner, or jointly worked through the exercises. Do you think that some members of your group deserve a different grade from others?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdUW-GQS9XLZ",
        "colab_type": "text"
      },
      "source": [
        "Andrea Bonfanti: We all shared the work equally.\n",
        "\n",
        "Berk Isler: We all shared the work equally.\n",
        "\n",
        "Gokhan Simsek: We all shared the work equally."
      ]
    }
  ]
}